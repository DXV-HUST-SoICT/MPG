% -*- mode: LaTeX; -*- 
\chapter{Search}
\label{chap:m:search}

This chapter discusses how search is used for solving Gecode
models. Search involves two techniques: \emph{branching} and
\emph{exploration}. Branching defines the shape of the search
tree. Exploration defines a strategy how to explore parts of the
search tree and how to possibly modify the tree's shape during
exploration (for example, during branch-and-bound best solution
search by adding new constraints). This chapter restricts itself
to simple search engines to find solutions, Gist as an
interactive and graphical search engine is discussed in
\autoref{chap:m:gist}.

\paragraph{Overview.}

\mbox{}\autoref{sec:m:search:branch} explains important
details of how branching in Gecode can be used for modeling and
solving problems. This section belongs to the basic reading
material of \autoref{part:m}.

\autoref{sec:m:search:re} explains how search in Gecode makes use
of hybrid recomputation and why it is efficient. Even though this
section does not belong to the basic reading material, you are
highly encouraged to read it. 

\autoref{sec:m:search:parallel} explains how parallel search can
be used in Gecode and what can be expected of parallel search in
principle. How search engines can be used is explained in
\autoref{sec:m:search:simple}.

\begin{convention}
  Note that the same conventions hold as in \autoref{chap:m:int}.
\end{convention}

\section{Branching}
\label{sec:m:search:branch}

A space in Gecode can have \emph{several} branchers posted on
behalf of a \emph{branching} that are
executed in order of creation. Assume that in
\begin{code}
branch(home, x, INT_VAR_SIZE_MIN(), INT_VAL_MIN());
...
branch(home, y, INT_VAR_SIZE_MIN(), INT_VAL_MIN());
\end{code}
both calls to \?branch? create a brancher. Search branches first
on the variables \?x? and then on the variables \?y?. Here, it
does not matter whether propagators are created in between the
creation of branchers.

\subsection{Branching on integer and Boolean variables}
\label{sec:m:search:branch:int}

\begin{important}
\begin{samepage}
Do not forget to add
\begin{code}
#include <gecode/int.hh>
\end{code}
\end{samepage}
to your program when you want to branch on integer and
Boolean variables.
\end{important}

Gecode offers predefined \emph{variable-value branching}: when
calling \?branch? to post a branching, the third argument defines
which variable is selected for branching, whereas the fourth
argument defines which values are selected for branching. For
example, for an array of integer or Boolean variables \?x? the
following call to branch
\begin{code}
branch(home, x, INT_VAR_MIN_MIN(), INT_VAL_SPLIT_MIN());
\end{code}
selects a variable $y$ with the smallest minimum value (in case
of ties, the first such variable in \?x? is selected) and creates
a choice with two alternatives $y\leq n$ and $y>n$ where
$$n=\left\lfloor\frac{\min(y)+\max(y)}{2}\right\rfloor$$ 
The posted brancher assigns all
variables and then ceases to exist. If more branchers exist,
search continues with the next brancher.

The \?branch()? function also accepts a branch filter function as
optional last argument, see \autoref{sec:m:search:branch:filter}
for details.

\begin{figure}
\begin{center}
\begin{tabular}{l@{\quad}l}
\?INT_VAR_NONE()? & first unassigned\\
\?INT_VAR_RND(r)? & randomly\\
\?INT_VAR_MIN(m,?\OptArg{\?t?}\?)? & smallest value of merit function \?m?\\
\?INT_VAR_MAX(m,?\OptArg{\?t?}\?)? & largest value of merit function \?m?\\
\?INT_VAR_DEGREE_MIN(?\OptArg{\?t?}\?)? & smallest degree\\
\?INT_VAR_DEGREE_MAX(?\OptArg{\?t?}\?)? & largest degree\\
\?INT_VAR_AFC_MIN(?\OptArg{\?t?}\?)? & smallest accumulated failure count (AFC)\\
\?INT_VAR_AFC_MAX(?\OptArg{\?t?}\?)? & largest accumulated failure count (AFC)\\
\?INT_VAR_ACTIVITY_MIN(a,?\OptArg{\?t?}\?)? & lowest activity\\
\?INT_VAR_ACTIVITY_MAX(a,?\OptArg{\?t?}\?)? & highest activity\\
\?INT_VAR_MIN_MIN(?\OptArg{\?t?}\?)? & smallest minimum value\\
\?INT_VAR_MIN_MAX(?\OptArg{\?t?}\?)? & largest minimum value\\
\?INT_VAR_MAX_MIN(?\OptArg{\?t?}\?)? & smallest maximum value\\
\?INT_VAR_MAX_MAX(?\OptArg{\?t?}\?)? & largest maximum value\\
\?INT_VAR_SIZE_MIN(?\OptArg{\?t?}\?)? & smallest domain size\\
\?INT_VAR_SIZE_MAX(?\OptArg{\?t?}\?)? & largest domain size\\
\?INT_VAR_SIZE_DEGREE_MIN(?\OptArg{\?t?}\?)? & smallest domain size divided by degree\\
\?INT_VAR_SIZE_DEGREE_MAX(?\OptArg{\?t?}\?)? & largest domain size divided by degree\\
\?INT_VAR_SIZE_AFC_MIN(?\OptArg{\?t?}\?)? & smallest domain size divided by AFC\\
\?INT_VAR_SIZE_AFC_MAX(?\OptArg{\?t?}\?)? & largest domain size divided by AFC\\
\?INT_VAR_SIZE_ACTIVITY_MIN(a,?\OptArg{\?t?}\?)? & smallest domain size divided by activity\\
\?INT_VAR_SIZE_ACTIVITY_MAX(a,?\OptArg{\?t?}\?)? & largest domain size divided by activity\\
\?INT_VAR_REGRET_MIN_MIN(?\OptArg{\?t?}\?)? & smallest minimum-regret\\
\?INT_VAR_REGRET_MIN_MAX(?\OptArg{\?t?}\?)? & largest minimum-regret\\
\?INT_VAR_REGRET_MAX_MIN(?\OptArg{\?t?}\?)? & smallest maximum-regret\\
\?INT_VAR_REGRET_MAX_MAX(?\OptArg{\?t?}\?)? & largest
maximum-regret\\
\end{tabular}
\end{center}
\caption{Integer and Boolean variable selection}
\label{fig:m:search:int:var}
\end{figure}

For integer and Boolean variables, variable selection is defined
by a value of class \gecoderef[class]{IntVarBranch} (see also
\gecoderef[group]{TaskModelIntBranchVar}) and value selection is defined
by a value of type \gecoderef[class]{IntValBranch}  (see also
\gecoderef[group]{TaskModelIntBranchVal}). 

For an overview of the available variable selection strategies,
see \autoref{fig:m:search:int:var}. Here, an argument \?r? refers
to a random number generator of type
\gecoderef[class]{Rnd}. Using random number generators for
branching is discussed in
\autoref{sec:m:search:branch:rnd}. The argument \?m? refers to a
user-defined merit function of type
\gecoderef[typedef]{IntBranchMerit} for integer variables and
\gecoderef[typedef]{BoolBranchMerit} for Boolean
variables. User-defined merit functions are discussed in \autoref{sec:m:search:branch:user-var}.
The argument \?a? refers to
activity information for integer variables (of type
\gecoderef[class]{IntActivity}) or Boolean variables (of type
\gecoderef[class]{BoolActivity}). For a discussion of activity,
see \autoref{sec:m:search:branch:shared}. The optional argument
\?t? refers to a tie-breaking limit function of type
\gecoderef[typedef]{BranchTbl} and is discussed in 
\autoref{sec:m:search:branch:tbl}.

\begin{figure}
\begin{center}
\begin{tabular}{l@{\quad}l}
\?INT_VAL_RND(r)? & random value\\
\?INT_VAL(v,?\OptArg{\?c?}\?)? & defined by value function \?v? and commit
function \?c?\\
\?INT_VAL_MIN()? & smallest value\\
\?INT_VAL_MED()? & greatest value not greater than the median\\
\?INT_VAL_MAX()? & largest value\\
\?INT_VAL_SPLIT_MIN()? & values not greater than mean of smallest
  and largest value\\
\?INT_VAL_SPLIT_MAX()? & values greater than mean of smallest
  and largest value\\
\?INT_VAL_RANGE_MIN()? & values from smallest range, if domain has
several ranges;\\
& otherwise, values not greater than mean of smallest\\&
  and largest value\\
\?INT_VAL_RANGE_MAX()? & values from largest range, if domain has
several ranges;\\
& otherwise, values greater than mean of smallest
  and largest value\\
\?INT_VALUES_MIN()? & all values starting from smallest\\
\?INT_VALUES_MAX()? & all values starting from largest\\
\end{tabular}
\end{center}
\caption{Integer and Boolean value selection}
\label{fig:m:search:int:val}
\end{figure}

An overview of the available value selection strategies for
integer and Boolean variables can be found in
\autoref{fig:m:search:int:val}. Here, an argument \?r? refers to
a random number generator of type \gecoderef[class]{Rnd} which is
discussed in \autoref{sec:m:search:branch:rnd}. An argument \?v?
refers to a value selection function of type
\gecoderef[typedef]{IntBranchVal} for integer variables and
\gecoderef[typedef]{BoolBranchVal} for Boolean variables. An
optional argument \?c? refers to a commit function of type
\gecoderef[typedef]{IntBranchCommit} for integer variables and of
type \gecoderef[typedef]{BoolBranchCommit} for Boolean variables.
Value and commit function are discussed in
\autoref{sec:m:search:branch:user-val}.

\tip{Variables are re-selected during branching}{
\label{tip:m:search:reselected}
A variable-value branching selects a variable for each choice
it creates. Consider as an example a script using an integer
variable array \?x? with three variables and domains
$\range{1}{4}$ created by
\begin{code}
IntVarArray x(home, 3, 1, 4);
\end{code}

\begin{samepage}
Let us assume that no constraints are posted on the variables in
\?x? and that a branching is posted by
\begin{code}
branch(home, x, INT_VAR_SIZE_MAX(), INT_VAL_SPLIT_MIN());
\end{code}
\end{samepage}

The branching starts by selecting \?x[0]? as the first variable with the
largest domain in the array \?x? and creates the choice
$$
(\mbox{\?x[0]?}\leq 2)\vee
(\mbox{\?x[0]?}> 2)
$$

Now assume that search explores the first alternative which
results in the domain $\{1,2\}$ for \?x[0]?. When search continues,
the branching again selects the first variable with a largest
domain: hence \?x[1]? is selected and \emph{not} \?x[0]?.

In other words, a variable-value branching does not stick to a
selected variable until the variable becomes assigned. Instead, a
variable-value branching re-selects a variable for each choice it
creates.  }

\tip{Do not try all values}{%
  Note that for \?INT_VALUES_MIN()? and \?INT_VALUES_MAX()?, a
  variable-value branching creates a choice for each selected
  variable with one alternative per value of the variable.

  This is typically a poor choice, as none of the alternatives
  can benefit from propagation that arises when other values of
  the same variable are tried. These branchings exist for
  instructional purposes (well, they do create beautiful trees in
  Gist). }


\subsection{Branching on set variables}
\label{sec:m:search:branch:set}

\begin{important}
Do not forget to add
\begin{code}
#include <gecode/set.hh>
\end{code}
to your program when you want to branch on set variables.
\end{important}

\begin{figure}
\begin{center}
\begin{tabular}{l@{\quad}l}
\?SET_VAR_NONE()? & first unassigned\\
\?SET_VAR_RND(r)? & randomly\\
\?SET_VAR_MIN(m,?\OptArg{\?t?}\?)? & smallest value of merit function \?m?\\
\?SET_VAR_MAX(m,?\OptArg{\?t?}\?)? & largest value of merit function \?m?\\
\?SET_VAR_DEGREE_MIN(?\OptArg{\?t?}\?)? & smallest degree\\
\?SET_VAR_DEGREE_MAX(?\OptArg{\?t?}\?)? & largest degree\\
\?SET_VAR_AFC_MIN(?\OptArg{\?t?}\?)? & smallest accumulated failure count (AFC)\\
\?SET_VAR_AFC_MAX(?\OptArg{\?t?}\?)? & largest accumulated failure count (AFC)\\
\?SET_VAR_ACTIVITY_MIN(a,?\OptArg{\?t?}\?)? & lowest activity\\
\?SET_VAR_ACTIVITY_MAX(a,?\OptArg{\?t?}\?)? & highest activity\\
\?SET_VAR_MIN_MIN(?\OptArg{\?t?}\?)? & smallest minimum unknown element\\
\?SET_VAR_MIN_MAX(?\OptArg{\?t?}\?)? & largest minimum unknown element\\
\?SET_VAR_MAX_MIN(?\OptArg{\?t?}\?)? & smallest maximum unknown element\\
\?SET_VAR_MAX_MAX(?\OptArg{\?t?}\?)? & largest maximum unknown element\\
\?SET_VAR_SIZE_MIN(?\OptArg{\?t?}\?)? & smallest unknown set\\
\?SET_VAR_SIZE_MAX(?\OptArg{\?t?}\?)? & largest unknown set\\
\?SET_VAR_SIZE_DEGREE_MIN(?\OptArg{\?t?}\?)? & smallest domain size divided by degree\\
\?SET_VAR_SIZE_DEGREE_MAX(?\OptArg{\?t?}\?)? & largest domain size divided by degree\\
\?SET_VAR_SIZE_AFC_MIN(?\OptArg{\?t?}\?)? & smallest domain size divided by AFC\\
\?SET_VAR_SIZE_AFC_MAX(?\OptArg{\?t?}\?)? & largest domain size divided by AFC\\
\?SET_VAR_SIZE_ACTIVITY_MIN(a,?\OptArg{\?t?}\?)? & smallest domain size divided by activity\\
\?SET_VAR_SIZE_ACTIVITY_MAX(a,?\OptArg{\?t?}\?)? & largest domain size divided by activity
\end{tabular}
\end{center}
\caption{Set variable selection}
\label{fig:m:search:set:var}
\end{figure}

For set variables, variable selection is defined
by a value of class \gecoderef[class]{SetVarBranch} (see also
\gecoderef[group]{TaskModelSetBranchVar}) and value selection is defined
by a value of type \gecoderef[class]{SetValBranch}  (see also
\gecoderef[group]{TaskModelSetBranchVal}). 

For an overview of the available variable selection strategies,
see \autoref{fig:m:search:set:var}. Here, an argument \?r? refers
to a random number generator of type
\gecoderef[class]{Rnd}. Using random number generators for
branching is discussed in
\autoref{sec:m:search:branch:rnd}. The argument \?m? refers to a
user-defined merit function of type
\gecoderef[typedef]{SetBranchMerit}. User-defined merit functions are discussed in \autoref{sec:m:search:branch:user-var}.
The argument \?a? refers to
activity information for set variables (of type
\gecoderef[class]{SetActivity}). For a discussion of activity,
see \autoref{sec:m:search:branch:shared}. The optional argument
\?t? refers to a tie-breaking limit function of type
\gecoderef[typedef]{BranchTbl} and is discussed in 
\autoref{sec:m:search:branch:tbl}.


\begin{figure}
\begin{center}
\begin{tabular}{l@{\quad}l}
\?SET_VAL_RND_INC(r)? &include random element\\
\?SET_VAL_RND_EXC(r)? &exclude random element\\
\?SET_VAL(v,?\OptArg{\?c?}\?)? & defined by value function \?v? and commit
function \?c?\\
\?SET_VAL_MIN_INC()? &include smallest element\\
\?SET_VAL_MIN_EXC()? &exclude smallest element\\
\?SET_VAL_MED_INC()? &include median element (rounding downwards)\\
\?SET_VAL_MED_EXC()? &exclude median element (rounding downwards)\\
\?SET_VAL_MAX_INC()? &include largest element\\
\?SET_VAL_MAX_EXC()? &exclude largest element\\
\end{tabular}
\end{center}
\caption{Set value selection}
\label{fig:m:search:set:val}
\end{figure}

An overview of the available value selection strategies for set
variables can be found in \autoref{fig:m:search:set:val}. Here,
an argument \?r? refers to a random number generator of type
\gecoderef[class]{Rnd} which is discussed in
\autoref{sec:m:search:branch:rnd}. An argument \?v? refers to a
value selection function of type
\gecoderef[typedef]{SetBranchVal}. An argument \?c? refers to a
commit function of type \gecoderef[typedef]{SetBranchCommit}.
Value and commit function are discussed in
\autoref{sec:m:search:branch:user-val}.


\subsection{Branching on float variables}
\label{sec:m:search:branch:float}

\begin{important}
Do not forget to add
\begin{code}
#include <gecode/float.hh>
\end{code}
to your program when you want to branch on float variables.
\end{important}

\begin{figure}
\begin{center}
\begin{tabular}{l@{\quad}l}
\?FLOAT_VAR_NONE()? & first unassigned\\
\?FLOAT_VAR_RND(r)? & randomly\\
\?FLOAT_VAR_MIN(m,?\OptArg{\?t?}\?)? & smallest value of merit function \?m?\\
\?FLOAT_VAR_MAX(m,?\OptArg{\?t?}\?)? & largest value of merit function \?m?\\
\?FLOAT_VAR_DEGREE_MIN(?\OptArg{\?t?}\?)? & smallest degree\\
\?FLOAT_VAR_DEGREE_MAX(?\OptArg{\?t?}\?)? & largest degree\\
\?FLOAT_VAR_AFC_MIN(?\OptArg{\?t?}\?)? & smallest accumulated failure count (AFC)\\
\?FLOAT_VAR_AFC_MAX(?\OptArg{\?t?}\?)? & largest accumulated failure count (AFC)\\
\?FLOAT_VAR_ACTIVITY_MIN(a,?\OptArg{\?t?}\?)? & lowest activity\\
\?FLOAT_VAR_ACTIVITY_MAX(a,?\OptArg{\?t?}\?)? & highest activity\\
\?FLOAT_VAR_MIN_MIN(?\OptArg{\?t?}\?)? & smallest minimum value\\
\?FLOAT_VAR_MIN_MAX(?\OptArg{\?t?}\?)? & largest minimum value\\
\?FLOAT_VAR_MAX_MIN(?\OptArg{\?t?}\?)? & smallest maximum value\\
\?FLOAT_VAR_MAX_MAX(?\OptArg{\?t?}\?)? & largest maximum value\\
\?FLOAT_VAR_SIZE_MIN(?\OptArg{\?t?}\?)? & smallest domain size\\
\?FLOAT_VAR_SIZE_MAX(?\OptArg{\?t?}\?)? & largest domain size\\
\?FLOAT_VAR_SIZE_DEGREE_MIN(?\OptArg{\?t?}\?)? & smallest domain size divided by degree\\
\?FLOAT_VAR_SIZE_DEGREE_MAX(?\OptArg{\?t?}\?)? & largest domain size divided by degree\\
\?FLOAT_VAR_SIZE_AFC_MIN(?\OptArg{\?t?}\?)? & smallest domain size divided by AFC\\
\?FLOAT_VAR_SIZE_AFC_MAX(?\OptArg{\?t?}\?)? & largest domain size divided by AFC\\
\?FLOAT_VAR_SIZE_ACTIVITY_MIN(a,?\OptArg{\?t?}\?)? & smallest domain size divided by activity\\
\?FLOAT_VAR_SIZE_ACTIVITY_MAX(a,?\OptArg{\?t?}\?)? & largest domain size divided by activity\\
\end{tabular}
\end{center}
\caption{Float variable selection}
\label{fig:m:search:float:var}
\end{figure}

For float variables, variable selection is defined
by a value of class \gecoderef[class]{FloatVarBranch} (see also
\gecoderef[group]{TaskModelFloatBranchVar}) and value selection is defined
by a value of type \gecoderef[class]{FloatValBranch}  (see also
\gecoderef[group]{TaskModelFloatBranchVal}). 

For an overview of the available variable selection strategies,
see \autoref{fig:m:search:float:var}. Here, an argument \?r?
refers to a random number generator of type
\gecoderef[class]{Rnd}. Using random number generators for
branching is discussed in \autoref{sec:m:search:branch:rnd}. The
argument \?m? refers to a user-defined merit function of type
\gecoderef[typedef]{FloatBranchMerit}. User-defined merit
functions are discussed in
\autoref{sec:m:search:branch:user-var}.  The argument \?a? refers
to activity information for float variables (of type
\gecoderef[class]{FloatActivity}). For a discussion of activity,
see \autoref{sec:m:search:branch:shared}. The optional argument
\?t? refers to a tie-breaking limit function of type
\gecoderef[typedef]{BranchTbl} and is discussed in
\autoref{sec:m:search:branch:tbl}.

\begin{figure}
\begin{center}
\begin{tabular}{l@{\quad}l}
\?FLOAT_VAL(v,?\OptArg{\?c?}\?)? & defined by value function \?v? and commit
function \?c?\\
\?FLOAT_VAL_SPLIT_RND(r)? &values not smaller or larger than mean
of smallest and largest value\\
& (smaller or larger is randomly selected)\\
\?FLOAT_VAL_SPLIT_MIN()? &values not greater than mean of smallest
  and largest value\\
\?FLOAT_VAL_SPLIT_MAX()? &values not smaller than mean of smallest
  and largest value\\
\end{tabular}
\end{center}
\caption{Float value selection}
\label{fig:m:search:float:val}
\end{figure}

An overview of the available value selection strategies for float
variables can be found in \autoref{fig:m:search:float:val}. Here,
an argument \?r? refers to a random number generator of type
\gecoderef[class]{Rnd} which is discussed in
\autoref{sec:m:search:branch:rnd}. An argument \?v? refers to a
value selection function of type
\gecoderef[typedef]{FloatBranchVal}. An argument \?c? refers to a
commit function of type \gecoderef[typedef]{FloatBranchCommit}.
Value and commit function are discussed in
\autoref{sec:m:search:branch:user-val}.


\subsection{Local versus shared variable selection criteria}
\label{sec:m:search:branch:shared}

The criteria used for selecting variables are either \emph{local}
or \emph{shared} criteria. A \emph{local} variable selection
criterion depends only on a brancher's home space. A
\emph{shared} variable selection criterion depends not only on
the brancher's home space but also on all spaces that have been
created during search sharing the same root space where the
brancher had originally been posted. That entails that a shared
criterion can use information that is collected during search. In
terms of \autoref{sec:m:search:re}, a shared variable selection
criterion depends on all equivalent spaces created by cloning.

\paragraph{Local variable selection criteria.}

All selection criteria but those based on \emph{AFC} and
\emph{activity} are local: they either select variables without
using any information on a
variable (\?INT_VAR_NONE()?), select variables randomly
(\?INT_VAR_RND(r)?, see also \autoref{sec:m:search:branch:rnd}), or
use the degree or domain of a variable for selection.

The \emph{degree} of a variable is the number of propagators
depending on the variable (useful as an approximate measure of
how constrained a variables is).

The \emph{minimum-regret} for integer and Boolean variables is
the difference between the smallest and second smallest value in
the domain of a variable (\emph{maximum-regret} is analogous).

\paragraph{Selection using accumulated failure count.}

The accumulated failure count (AFC) of a variable is a shared
selection criterion. It is defined as the sum of the AFCs of all
propagators depending on the variable plus its degree (to give a
good initial value if the AFCs of all propagators are still
zero). The AFC of a propagator counts how often the propagator
has failed during search.  

The AFC of a variable is also known as the weighted degree of a
variable~\cite{AFC}.

\paragraph{Selection using activity.}

The activity of a variable is a shared criterion and captures how
much a variable has been involved in constraint propagation.

The activity of a variable is maintained by constraint
propagation as follows. Each time constraint propagation finishes
during search (by executing the \?status()? function of a space,
see also \autoref{tip:m:started:status}), the activity of a
variable $\mathtt x$ is updated as follows~\cite{activity}:
\begin{itemize}
\item If the variable \?x? has not been pruned (that is, no
  values have been removed from the domain of \?x? through
  propagation), the activity $\alpha(\mathtt x)$ of \?x? is
  updated by a decay-factor $\gamma$ ($0<\gamma\leq 1$):
$$\alpha(\mathtt x)=\gamma\cdot\alpha(\mathtt x)$$
\item If the variable \?x? has been pruned, the activity
  $\alpha(\mathtt x)$ of \?x? is incremented by $1$:
$$\alpha(\mathtt x)=\alpha(\mathtt x)+1$$
\end{itemize}

In order to use activity for branching, one must create an object
of class \gecoderef[class]{IntActivity} for integer variables, an
object of class \gecoderef[class]{BoolActivity} for Boolean
variables, an object of class \gecoderef[class]{SetActivity} for
set variables, or an object of class
\gecoderef[class]{FloatActivity} for float variables. The object
is responsible for recording activity information.

If \?x? is an integer variable array, then
\begin{code}
IntActivity a(home,x,0.99);
\end{code}
initializes the activity information \?a? for the variables in \?x?
with decay-factor $\gamma=\mathtt{0.99}$. 

The decay-factor can
later be changed, say to $\gamma=\mathtt{0.95}$, by
\begin{code}
a.decay(0.95);
\end{code}
and \?a.decay()? returns the current decay-factor of \?a?.

A branching for integer variables using activity information must
be given an object of type \?IntActivity? by providing an
additional argument as follows:
\begin{code}
branch(home, x, INT_VAR_ACTIVITY_MAX(a), INT_VAL_MIN());
\end{code}
Here the integer variable array \?x? must be exactly the same
that has been used for creating the integer activity object
\?a?. 

Activity for other variable types is analogous.



\subsection{Random variable and value selection}
\label{sec:m:search:branch:rnd}

One particular strategy for variable and value selection is by
random. For integer and Boolean variables, \?INT_VAR_RND(r)?
selects a random variable and \?INT_VAL_RND(r)? selects a random
value where \?r? is a random number generator of class
\gecoderef[class]{Rnd}.  For set variables, \?SET_VAR_RND(r)?
selects a random variable and \?SET_VAL_RND_INC(r)? and
\?SET_VAL_RND_EXC(r)? include and exclude a random value from a
set variable. For float variables, \?FLOAT_VAR_RND(r)? selects a
random variable and \?FLOAT_VAL_SPLIT_RND(r)? randomly selects
the lower or upper half of the domain of a float variable.

The random number generators used for random variable and value
selection follow a uniform distribution and must be initialized by
a seed value. For example, a random number generator \?r? is
created and initialized with a seed value of \?1? (the seed value
must be an \?unsigned int?) by
\begin{code}
Rnd r(1U);
\end{code}T
he seed value can be changed with the \?seed()? function (if
needed, the \?seed()? function initializes the random number
generator). For example, by
\begin{code}
r.seed(2U);
\end{code}
the seed value is set to \?2? (the \?seed()? function also
expects an argument of type \?unsigned int?).

A random number generator is passed by reference to the
brancher. In the terms of \autoref{sec:m:integer:proper}, a
random number generator is a proper data structure. When a random
number generator is stored as a member of a space it must be
updated by using the \?update()? function of the random number
generator.

It is possible to use the same random number generator for both
variable and value selection. For example, by
\begin{code}
Rnd r(1U);
branch(home, x, INT_VAR_RND(r), INT_VAL_RND(r));
\end{code}
both the variable in \?x? as well as its value is randomly
selected using the numbers generated by \?r?. It is of course
also possible to use two separate random number generators as in:
\begin{code}
Rnd r1(1U), r2(1U);
branch(home, x, INT_VAR_RND(r1), INT_VAL_RND(r2));
\end{code}



\subsection{User-defined variable selection}
\label{sec:m:search:branch:user-var}

Variables can be selected according to user-defined criteria
implemented as a \emph{merit function}. For integer variables,
the type of the merit function is
\gecoderef[typedef]{IntBranchMerit}, for Boolean variables
\gecoderef[typedef]{BoolBranchMerit}, set set variables
\gecoderef[typedef]{SetBranchMerit}, and for float variables
\gecoderef[typedef]{FloatBranchMerit}. For integer variables, the
type is defined as
\begin{code}
typedef double (*IntBranchMerit)(const Space& home, 
                                 const IntVar& x, int i);
\end{code}
where \?home? refers to the home space, \?x? is the integer
variable for which a merit value should be computed and \?i?
refers to the position of \?x? in the integer variable array
passed as argument to the \?branch()? function. The merit
function types for Boolean, set, and float variables are
analogous.

For example, the following static merit function
\begin{code}
static double m(const Space& home, const IntVar& x, int i) {
  return x.size();
}
\end{code}
simply returns the domain size of the integer variable \?x? as
merit value. The merit function can be used to select a
variable with either smallest or largest merit value. By
\begin{code}
branch(home, INT_VAR_MIN(&m). INT_VAL_MIN());
\end{code}
a variable with least merit value according to the merit function
\?m()? is selected (that is, the first variable in the array with
smallest size). A variable with maximal merit value is selected
by: 
\begin{code}
branch(home, INT_VAR_MAX(&m). INT_VAL_MIN());
\end{code}

\tip{Using a member function as merit function}{
\label{tip:m:search:merit}%
Often it is more convenient to use a const member function instead of a
static function as a merit function. This is in particular the
case when the merit function needs access to members of a
script. For example, the following member function of a class
\?Model? for a script (a subclass of \gecoderef[class]{Space}):
\begin{code}
double merit(const IntVar& x, int i) const {
  return ...;
}
\end{code}
is used when defining a static function as follows
\begin{code}
double trampoline(const Space& home, const IntVar& x, int i) {
  return static_cast<const Model&>(home).merit(x,i);
\end{code}
and passing a pointer to \?trampoline()? as an argument to
\?INT_VAR_MIN()? or \?INT_VAR_MAX()?.
}


\subsection{User-defined value selection}
\label{sec:m:search:branch:user-val}


The value selected for branching and how the selected value is
used for branching can be defined by \emph{branch value
  functions} and \emph{branch commit functions}. 

\begin{figure}
\begin{center}
\begin{tabular}{|l||l|l|}
\hline
Variable type & Value function type & Value type\\
\hline\hline
\gecoderef[class]{IntVar} & \gecoderef[typedef]{IntBranchVal} &
\?int?\\\hline
\gecoderef[class]{BoolVar} & \gecoderef[typedef]{BoolBranchVal} &
\?int?\\\hline
\gecoderef[class]{SetVar} & \gecoderef[typedef]{SetBranchVal} &
\?int?\\\hline
\gecoderef[class]{FloatVar} & \gecoderef[typedef]{FloatBranchVal}
&\gecoderef[typedef]{FloatNum}\\\hline
\end{tabular}
\end{center}
\caption{Branch value functions}
\label{fig:m:search:val}
\end{figure}

A branch value function takes a constant reference to a space and
a variable and returns a value, where the type of the value
depends on the variable type. \autoref{fig:m:search:val} lists
the branch value function types and the value types for the
different variable types. For example, the type for value
functions for integer variables is defined as:
\begin{code}
typedef int (*IntBranchVal)(const Space& home, const IntVar& x);
\end{code}

A branch commit function takes a reference to a space, the number
of the alternative \?a? (\?0? for the first alternative and \?1?
for the second alternative), a variable, and a value selected by
a branch value function. For example, the type definition for
branch commit functions for integer variables is:
\begin{code}
typedef void (*IntBranchCommit)(Space& home, unsigned int a,
                                IntVar x, int n);
\end{code}

Let us consider \?INT_VAL_MIN()? implemented by value and
commit functions. The value function can be defined as:
\begin{code}
static int v(const Space& home, const IntVar& x) {
  return x.min();
}
\end{code}
and the commit function as:
\begin{code}
static void c(Space& home, unsigned int a,
              IntVar x, int n) {
  if (a == 0U) {
    rel(home, x, IRT_EQ, n);
  } else {
    rel(home, x, IRT_NQ, n);
  }
}
\end{code}
A branching using the value and commit function then can be
posted by:
\begin{code}
branch(home, x, INT_VAR_NONE(), INT_VAL(&v,&c));
\end{code}

The commit function is optional. If the commit function is
omitted, a default commit function depending on the variable type
is used. For integer variables, for example, the commit function
corresponds to the commit function from the previous
example. Hence, it is sufficient to post the brancher as:
\begin{code}
branch(home, x, INT_VAR_NONE(), INT_VAL(&v));
\end{code}

\begin{figure}
\begin{center}
\begin{tabular}{|l||l|l|}
\hline
Variable type & Commit function type & Default behavior\\
\hline\hline
\gecoderef[class]{IntVar} & \gecoderef[typedef]{IntBranchCommit} &
$(\mathtt{x}=\mathtt{n})\vee(\mathtt{x}\neq\mathtt{n})$\\\hline
\gecoderef[class]{BoolVar} & \gecoderef[typedef]{BoolBranchCommit} &
$(\mathtt{x}=\mathtt{n})\vee(\mathtt{x}\neq\mathtt{n})$\\\hline
\gecoderef[class]{SetVar} & \gecoderef[typedef]{SetBranchCommit} &
$(\mathtt{n}\in\mathtt{x})\vee(\mathtt{n}\not\in\mathtt{x})$\\\hline
\gecoderef[class]{FloatVar} &
\gecoderef[typedef]{FloatBranchCommit}&
$(\mathtt{x}\leq\mathtt{n})\vee(\mathtt{x}\geq\mathtt{n})$\\\hline
\end{tabular}
\end{center}
\caption{Branch commit functions}
\label{fig:m:search:commit}
\end{figure}

\autoref{fig:m:search:commit} lists the commit function types
and the behavior of the default commit function for the different
variable types. The variable \?x? refers to the variable selected
by the brancher and \?n? to the value selected by the branch
value function.

Note that both value and commit functions can also be implemented
as member functions, similar to merit functions as described in
\autoref{tip:m:search:merit}.

For examples using value functions for branching, see
\gecoderef[example]{black-hole} and \gecoderef[example]{bacp}.


\subsection{Tie-breaking}
\label{sec:m:search:branch:tie}
\label{sec:m:search:branch:tbl}

The default behavior for tie-breaking during variable selection
is that the first variable (that is the variable with the lowest
index in the array) satisfying the selection criteria is
selected. For many applications that is not sufficient.

A typical example for integer variables is to select a most
constrained variable first (the variable most propagators depend
on, that is, with largest degree). Then, among the most
constrained variables select the variable with the smallest
domain. This can be achieved by using a \?tiebreak()?  function:
\begin{code}
branch(home, x, tiebreak(INT_VAR_DEGREE_MAX(), INT_VAR_SIZE_MIN()),
                INT_VAL_MIN());
\end{code}
The overloaded function \?tiebreak()?  (see
\gecoderef[group]{TaskModelBranchTieBreak}) takes up to four
variable selection values.

Random selection is particularly interesting for tie-breaking. For
example, breaking ties by first selecting a variable with
smallest domain and then selecting a random variable among those
with smallest domain:
\begin{code}
branch(home, x, tiebreak(INT_VAR_SIZE_MIN(), INT_VAR_RND(r)),
                INT_VAL_MIN());
\end{code}
Here, \?r? must be a random number generator as discussed in
\autoref{sec:m:search:branch:rnd}.

\paragraph{Using tie-breaking limit functions.}

In the discussion so-far only exact ties have been considered.
Often it necessary to consider several variables as ties even
though some of them are not among the best variables. 
Which variables are considered as ties can be controlled by
\emph{tie-breaking limit functions}.

A tie-breaking limit function has the type
\gecoderef[typedef]{BranchTbl} which is defined as:
\begin{code}
typedef double (*BranchTbl)(const Space& home, double w, double b);
\end{code}
The function takes a constant reference to a space \?home? and
the worst merit value \?w? and the best merit value \?b? as
arguments. The value returned by the function determines which
variables are considered as ties.

Let us consider an example where we branch over four integer
variables from the integer variable array \?x? where the domains
of the variables are as follows:
$$
\mbox{\?x[0]?}\in\{1,2,3,4\}\qquad
\mbox{\?x[1]?}\in\{2,3,4\}\qquad
\mbox{\?x[2]?}\in\{1,2,4\}\qquad
\mbox{\?x[3]?}\in\{1,2,3,4,5,6,7\}
$$
Without the use of a tie-breaking limit function tie breaking as
in (here, \?r? is a random number generator):
\begin{code}
branch(home, x, tiebreak(INT_VAR_SIZE_MIN(), INT_VAR_RND(r)),
                INT_VAL_MIN());
\end{code}
the variables \?x[1]? and \?x[2]? (both with size as the merit value $3.0$) are considered as ties and
random variable selection will choose one of them. Likewise, when
branching with
\begin{code}
branch(home, x, tiebreak(INT_VAR_SIZE_MAX(), INT_VAR_RND(r)),
                INT_VAL_MIN());
\end{code}
only variable \?x[3]? will be considered as the single variable
with the best merit value $7.0$.

The following tie-breaking limit function (defined as a static
member function of a script, see also
\autoref{tip:m:search:merit}):
\begin{code}
static double tbl(const Space& home,
                  double w, double b) {
  return (w + b) / 2.0;
}
\end{code}
returns the average of the worst merit value \?w? and the best
marit value \?b?. Using the function \?tbl()? for tie-breaking is
done by passing it as additional argument. 

For example, when using \?tbl()? with
\begin{code}
branch(home, x, tiebreak(INT_VAR_SIZE_MIN(&tbl), INT_VAR_RND(r)),
                INT_VAL_MIN());
\end{code}
the function \?tbl()? is called with $\mathtt{w}=7.0$ and
$\mathtt{b}=3.0$ and returns $(7.0 + 3.0)/2.0=5.0$. Hence,
the three variables \?x[0]?, \?x[1]?, and \?x[2]? are considered
for tie-breaking and random selection will make a choice among
these three variables.

For example, when using \?tbl()? with
\begin{code}
branch(home, x, tiebreak(INT_VAR_SIZE_MAX(&tbl), INT_VAR_RND(r)),
                INT_VAL_MIN());
\end{code}
the function \?tbl()? is called with $\mathtt{w}=3.0$ and
$\mathtt{b}=7.0$ and returns $(3.0 + 7.0)/2.0=5.0$. Hence,
only variable \?x[3]? is considered for tie-breaking.

Note that worse and best depends on whether the variable
selection tries to minimize or maximize the merit value. If a
tie-breaking limit function returns a value that is worse that
the worst merit value, all variables are considered for
tie-breaking. If a function returns a value that is better than
the best value, the returned value is ignored and the best value
is considered as limit (in which case, tie-breaking works exactly
the same as if not using a tie-breaking limit function at all).

\subsection{Using branch filter functions}
\label{sec:m:search:branch:filter}

By default, a variable-value branching continues to branch until
all variables passed to the branching are assigned. This behavior
can be changed by using a \emph{branch filter function}.

A branch filter function is called during branching for each
variable to be branched on. If the filter function returns
\?true?, the variable is considered for branching. Otherwise, the
variable is simply ignored.

A branch filter function can be passed as the last (optional)
argument when calling the \?branch()? function. 

The type of a branch filter function depends on the variable
type. For integer variables, the type
\gecoderef[typedef]{IntBranchFilter} is defined as
\begin{code}
typedef bool (*IntBranchFilter)(const Space& home,
                                const IntVar& x, int i);
\end{code}
That is, a branch filter function takes the \?home? space and the
position \?i? of the variable \?x? as argument. The position \?i?
refers to the position of the variable \?x? in the array of
variables used for posting the branching. For Boolean variables,
the type is \gecoderef[typedef]{BoolBranchFilter}, for set
variables \gecoderef[typedef]{SetBranchFilter}, and for float
variables \gecoderef[typedef]{FloatBranchFilter}.

\begin{litcode}[texonly]{branch filter function sketch}
class Model : public Space {
protected:
  IntVarArray x;
public:
  Model(void) : ... {
    \begin{litblock}{anonymous}
    \end{litblock}
    \begin{litblock}{post branching}
    branch(home, x, ..., ..., &filter);
    \end{litblock}
  }
  \begin{litblock}{anonymous}
  \end{litblock}
  \begin{litblock}{define filter function}
  static bool filter(const Space& home, const IntVar& y, int i) {
    return y.size() >= 4;
  }
  \end{litblock}
};
\end{litcode}

\begin{figure}
\insertlitcode{branch filter function sketch}
\caption{Model sketch for branch filter function}
\label{fig:m:search:branch:filter:sketch}
\end{figure}

Assume, for example, that we want to branch only on variables from
a variable array \?x? for branching with a domain size of at
least \?4?. Consider the sketch of a model shown in
\autoref{fig:m:search:branch:filter:sketch}. 

The branch filter function can be defined as a static member
function of the class \?Model? as follows:
\insertlitcode{branch filter function sketch:define filter function}

Specifying that the branching should use the filter function is done
as follows:
\insertlitcode{branch filter function sketch:post branching}

In many cases it can be more convenient to perform the actual
filtering in a \?const? member function. This can be done along
the lines of \autoref{tip:m:search:merit}.


\subsection{Assigning integer, Boolean, set, and float variables}
\label{sec:m:search:branch:assign}

A special variant of branching is \emph{assigning} variables: for
a not yet assigned variable the branching creates a single
alternative which assigns the variable a value. The effect of
assigning is that assignment is interleaved with constraint
propagation. That is, after an assignment has been done, the next
assignment will be done only after the effect of the previous
assignment has been propagated.

\begin{figure}
\begin{center}

\subfigure{
\begin{tabular}{l@{\quad}l}
\?INT_ASSIGN_MIN()?  & smallest value\\
\?INT_ASSIGN_MED()?  & median value (rounding downwards)\\
\?INT_ASSIGN_MAX()?  & maximum value\\
\?INT_ASSIGN_RND(r)? & random value\\
\?INT_ASSIGN(v,?\OptArg{\?c?}\?)? & defined by value function
\?v? and commit function \?c?\\
\end{tabular}}

\subfigure{
\begin{tabular}{l@{\quad}l}
\?SET_ASSIGN_MIN_INC()? & include smallest element\\
\?SET_ASSIGN_MIN_EXC()? & exclude smallest element\\
\?SET_ASSIGN_MED_INC()? & include median element (rounding downwards)\\
\?SET_ASSIGN_MED_EXC()? & exclude median element (rounding downwards)\\
\?SET_ASSIGN_MAX_INC()? & include largest element\\
\?SET_ASSIGN_MAX_EXC()? & exclude largest element\\
\?SET_ASSIGN_RND_INC(r)? & include random element\\
\?SET_ASSIGN_RND_EXC(r)? & exclude random element\\
\?SET_ASSIGN(v,?\OptArg{\?c?}\?)? & defined by value function
\?v? and commit function \?c?\\
\end{tabular}}

\subfigure{
\begin{tabular}{l@{\quad}l}
\?FLOAT_ASSIGN_MIN()? & median value of lower part\\
\?FLOAT_ASSIGN_MAX()? & median value of upper part\\
\?FLOAT_ASSIGN_RND(r)? & median value of randomly chosen part\\
\?FLOAT_ASSIGN(v,?\OptArg{\?c?}\?)? & defined by value function
\?v? and commit function \?c?\\
\end{tabular}}

\end{center}
\caption{Value selection for assigning variables}
\label{fig:m:search:assign}
\end{figure}

For example, the next code fragment assigns all integer variables
in \?x?  their smallest possible value:
\begin{code}
assign(home, x, INT_ASSIGN_MIN());
\end{code}
The strategy to select the value to be assigned is defined by a
value of class \gecoderef[class]{IntAssign} (see also (see also
\gecoderef[group]{TaskModelIntBranchAssign}) for integer and
Boolean variables, by a value of class
\gecoderef[class]{SetAssign} (see also (see also
\gecoderef[group]{TaskModelSetBranchAssign}) for set variables,
and by a value of class \gecoderef[class]{FloatAssign} (see also
(see also \gecoderef[group]{TaskModelFloatBranchAssign}) for
float variables.  

\autoref{fig:m:search:assign} summarizes the
value selection strategies for assigning integer, Boolean, set,
and float variables. Here, an argument \?r? refers to
a random number generator of type \gecoderef[class]{Rnd} which is
discussed in \autoref{sec:m:search:branch:rnd}. An argument \?v?
refers to a value selection function of type
\gecoderef[typedef]{IntBranchVal} for integer variables,
\gecoderef[typedef]{BoolBranchVal} for Boolean variables,
\gecoderef[typedef]{SetBranchVal} for set variables, and
\gecoderef[typedef]{FloatBranchVal} for float variables. An
optional argument \?c? refers to a commit function of type
\gecoderef[typedef]{IntBranchCommit} for integer variables, of
type \gecoderef[typedef]{BoolBranchCommit} for Boolean variables,
of type \gecoderef[typedef]{SetBranchCommit} for set variables,
and of type \gecoderef[typedef]{FloatBranchCommit} for float variables.
Value and commit function can be used in the same way for
assigning than for branching as described in
\autoref{sec:m:search:branch:user-val}. The only difference is
that the number of the alternative passed to the commit function
is always zero (as there is only a single alternative). 

An assignment also accepts a branch filter function as described
in \autoref{sec:m:search:branch:filter}.

\subsection{Branching on and assigning single variables}
\label{sec:m:search:single}

In addition to branching on an array of variables or assigning an
array of variables, Gecode also supports branching on and
assigning a single variable.

For example, if \?x? is an integer variable of type \?IntVar?,
then
\begin{code}
branch(home, x, INT_VAL_MIN());
\end{code}
branches on the single variable \?x? by first trying the smallest
value of \?x?.

Assume that \?x? is an array of integer variables. Then the
following code
\begin{code}
for (int i=0; i<x.size(); i++)
  branch(home, x[i], INT_VAL_MIN());
\end{code}
is equivalent, albeit considerably less efficient, to
\begin{code}
branch(home, x, INT_VAR_NONE(), INT_VAL_MIN());
\end{code}

\subsection{Executing code between branchers}
\label{sec:m:search:branch:code}

\begin{litcode}[texonly]{exec}
class Model : public Space {
public:
  Model(void) : ... {
    \begin{litblock}{anonymous}
    \end{litblock}
    \begin{litblock}{post branchings}
    branch(home, x, INT_VAR_NONE(), INT_VAL_MIN());
    branch(home, &Model::post);
    \end{litblock}
  }
  \begin{litblock}{anonymous}
  \end{litblock}
  \begin{litblock}{define functions}
  void more(void) {
    ...
  }
  static void post(Space& home) {
    static_cast<Model&>(home).more();
  }
  \end{litblock}
};
\end{litcode}

A common scenario is to post some constraints only after part of
the branching has been executed. This is supported in Gecode by a
brancher (see \gecoderef[group]{TaskModelBranchExec}) that
executes a function (either a function or a static member
function but not a member function). Suppose the following code
fragment defining a model \?Model?:
\insertlitcode[direct]{exec} 
where the constructor posts two branchers 
\insertlitcode{exec:post branchings}
The second branching takes a function pointer to the static
member function \?Model::post? which is defined as
\insertlitcode{exec:define functions}

As soon as the first branching is finished, the second branching
is executed. This branching provides just a single alternative
that calls the function \?Model::post? with the current space as
its argument. Then, the function casts the \?home? to \?Model&?
and calls \?more? on \?home?. While one could post the additional
constraints and/or branchings in \?Model::post? directly, the
member function \?Model::more? is more convenient to use.

\tip{Propagation is still explicit}{%
  It is tempting to believe that the variables in \?x? in the
  above example are all assigned when \?more()?  is executed.
  This is not necessarily true.

It will be true for the first time \?more()? is executed. But
\?more()? will be executed possibly quite often during
recomputation (see the following Section). And then, the only
guarantee one can rely on is that the brancher has created
enough alternatives to guarantee that the variables in \?x? are
assigned \emph{but only after constraint propagation has been
  performed} (see \autoref{tip:m:started:status}).  
}

\section{Hybrid recomputation}
\label{sec:m:search:re}

A central requirement for search is that it can return to
previous states: as spaces constitute nodes of the search tree, a
previous state is nothing but a space. Returning to a previous
space might be necessary because an alternative suggested by a
branching did not lead to a solution, or even if a solution has
been found more solutions might be requested.  As propagation and
branching change spaces, provisions must be taken that search can
actually return to a previous space, or an equivalent version of
that space.

Two space are \emph{equivalent} if propagation and branching and
hence search behave exactly the same on both spaces. Equivalent
spaces can be different, for example, they contain different yet
equivalent propagators, or are allocated at a different memory
area.

Gecode employs a hybrid of two techniques for restoring spaces:
\emph{recomputation} and \emph{cloning}.  

If you want to know how search engines can be programmed in
Gecode, please consult \autoref{part:s}.

\subsection{Cloning}

Cloning creates a clone of a space (this is supported by the
virtual \?copy?  member function as discussed in
\autoref{chap:m:started}). A clone and the original space are of
course equivalent. Restoration with cloning is straightforward:
before following a particular alternative during search, a clone
of the space is made and used later if necessary.

\subsection{Recomputation}
\label{sec:m:search:recomp}

Recomputation remembers what has happened during branching:
rather than storing an entire clone of a space just enough
information to redo the effect of a brancher is stored. The
information stored is called a \emph{choice} in
Gecode.  Redoing the effect is called to \emph{commit} a space:
given a space and a choice committing re-executes
the brancher as described by the choice and the
alternative to be explored (for example, left or right).

Consider the following part of a model, which constrains both
the sum and the product of \?x[0]? and \?x[1]? to be equal to
\?x[2]?:
\begin{code}
IntVarArray x(home, 3, 1, 6);
rel(home, x[0] + x[1] == x[2]);
mult(home, x[0], x[1], x[2]);
branch(home, x, INT_VAR_NONE(), INT_VAL_MIN());
\end{code}

\begin{figure}
\newcommand{\domINC}[2]{\{\mathtt{#1},\ldots,\mathtt{#2}\}}
\begin{center}
\begin{tabular}{c@{\qquad\qquad}c}
\begin{tabular}[c]{c}
\psset{xunit=0.04,yunit=0.04,runit=0.04}
\begin{pspicture}(96,152)(0,30)
\DefineNode{32}{143}{n1u}
\DefineNode{32}{133}{n1c}
 \DefineNode{48}{105}{n12u}
 \DefineNode{48}{95}{n12c}
  \DefineNode{64}{67}{n122u}
  \DefineNode{64}{57}{n122c}
   \DefineNode{80}{27}{n1222u}
   \DefineNode{80}{19}{n1222c}
   \DefineLink{n122c}{n1222u}
   \HiddenLinkL{n122c}{n1222c}{\footnotesize\quad$\mathtt{x[0]} \neq \mathtt 3$}
   \DefineNode{48}{27}{n1221u}
   \DefineNode{48}{19}{n1221c}
   \DefineLink{n122c}{n1221u}
   \HiddenLinkR{n122c}{n1221c}{\footnotesize$\mathtt{x[0]} = \mathtt 3$\quad}
  \DefineLink{n12c}{n122u}
  \HiddenLinkL{n12c}{n122c}{\footnotesize\quad$\mathtt{x[0]} \neq \mathtt 2$}
  \DefineNode{32}{67}{n121u}
  \DefineNode{32}{57}{n121c}
  \DefineLink{n12c}{n121u}
  \HiddenLinkR{n12c}{n121c}{\footnotesize$\mathtt{x[0]} = \mathtt 2$\quad}
 \DefineLink{n1c}{n12u}
 \HiddenLinkL{n1c}{n12c}{\footnotesize\quad$\mathtt{x[0]} \neq \mathtt 1$}
 \DefineNode{16}{103}{n11u}
 \DefineNode{16}{95}{n11c}
 \DefineLink{n1c}{n11u}
 \HiddenLinkR{n1c}{n11c}{\footnotesize$\mathtt{x[0]} = \mathtt 1$\quad}
\ChoiceNodeI{32}{133}{1}
 \ChoiceNodeI{48}{95}{3}
  \ChoiceNodeI{64}{57}{5}
   \FailedNodeI{80}{19}{7}
   \FailedNodeI{48}{19}{6}
  \SolvedNodeI{32}{57}{4}
 \FailedNodeI{16}{95}{2}
\end{pspicture}
\end{tabular}
&
\begin{tabular}[c]{|c||c|c|c|}
\hline
\textbf{node} & $\mathtt{x[0]}$ & $\mathtt{x[1]}$ & $\mathtt{x[2]}$ 
\\\hline\hline
1 & $\domINC{1}{5}$ & $\domINC{1}{5}$ & $\domINC{2}{6}$ 
\\\hline
3 & $\domINC{2}{5}$ & $\domINC{1}{3}$ & $\domINC{3}{6}$
\\\hline
4 & $\mathtt 2$             & $\mathtt 2$             & $\mathtt 4$
\\\hline
5 & $\domINC{3}{5}$ & $\domINC{1}{2}$ & $\domINC{4}{6}$
\\\hline
\end{tabular}
\end{tabular}
\end{center}

\caption{Example search tree}
\label{fig:m:search:tree}
\end{figure}

The corresponding search tree is shown in
\autoref{fig:m:search:tree}. A red box corresponds to a failed
node, a green diamond to a solution, and a blue circle to a
choice node (a node that has a not-yet finished brancher left).
An example choice for node~3 is
$\left(\mathtt{x[0]} = \mathtt 2\right) \vee \left(\mathtt{x[0]}
  \neq \mathtt 2\right)$ where the left alternative (or the
$0$-th alternative) is $\mathtt{x[0]} = \mathtt 2$ and the right
alternative ($1$-st alternative) is $\mathtt{x[0]} \neq \mathtt
2$.  Committing a space for node~3 to the $1$-st alternative
posts the constraint $\mathtt{x[0]} \neq \mathtt 2$.
     
More precisely, a choice does not store the actual
variables but the position among the variables of the brancher
(storing \?0? rather than \?x[0]?). By that, a choice can be used with an equivalent yet different space.
This is essential as the space used during recomputation will be
different from the space for which the choice has
been created.

\tip{Search is indeterministic}{
\label{tip:m:search:wmp}%
Gecode has been carefully designed to support non-monotonic
propagators: they are essential for example for randomized or
approximation propagation algorithms. A propagator in Gecode must
be \emph{weakly} monotonic: essentially, a propagator must be
correct but it does not need to always prune exactly the same
way. A consequence of this is that search is indeterministic: it
might be that two different searches find solutions in a
different order (possibly returning a different first solution)
or that the number of explored nodes is different. However,
search is always sound and complete: it never misses any
solution, it does not duplicate solutions, nor does it report
non-solutions as solutions.

If you want to know more about weakly monotonic propagators and
their interaction with search, we recommend to
consult~\cite{SchulteTack:CP:2009}.
}

\subsection{Hybrid recomputation}

The hybrid of recomputation and cloning works as follows. For
each new choice node, a choice is stored. Then,
every now and then search also stores a clone of a space (say,
every eight steps). Now, restoring a space at a certain position
in the search tree traverses the path in the tree upwards until a
clone $c$ is found on the path. Then recomputation creates a
clone $c'$ of $c$ (in certain cases, recomputation might use $c$
directly as an optimization). Then all choices on
the path are committed on $c'$ yielding an equivalent space.

\begin{figure}
\begin{center}
\psset{xunit=0.04,yunit=0.04,runit=0.04}
\begin{pspicture}(240,152)
\DefineNode{64}{143}{n1u}
\DefineNode{64}{133}{n1c}
\DefineNode{48}{105}{n2u}
\DefineNode{48}{95}{n2c}
\DefineNode{32}{67}{n3u}
\DefineNode{32}{57}{n3c}
\DefineNode{16}{27}{n4u}
\DefineNode{16}{19}{n4c}
\DefineNode{48}{27}{n5u}
\DefineNode{48}{19}{n5c}
\DefineLink{n1c}{n2u}
\DefineLink{n2c}{n3u}
\DefineLink{n3c}{n4u}
\DefineFatLink{n3c}{n5u}
   \ChoiceNodeI{64}{133}{1}
  \UChoiceNodeI{48}{95}{2}
 \UChoiceNodeI{32}{57}{3}
\FailedNodeI{16}{19}{4}
\GuessNode{48}{19}
\DefineNode{120}{133}{t1}
\DefineNode{120}{95}{t2}
\DefineNode{120}{57}{t3}
\DefineNode{120}{19}{t4}
\rput(120,133){\makebox(0,0)[l]{space $\mathtt c$ and choice
    $\mathtt{ch1}$}}
\rput(120,95){\makebox(0,0)[l]{choice $\mathtt{ch2}$}}
\rput(120,57){\makebox(0,0)[l]{choice $\mathtt{ch3}$}}
\ncline[nodesep=15]{->}{t1}{n1c}
\ncline[nodesep=15]{->}{t2}{n2c}
\ncline[nodesep=15]{->}{t3}{n3c}
\end{pspicture}
\end{center}

\caption{Hybrid recomputation}
\label{fig:m:search:hybrid}
\end{figure}

To recompute the node \texttt{?} for the example shown in
\autoref{fig:m:search:hybrid}, the following operations are
executed:
\begin{code}
Space* s = c->clone();
s->commit(ch1, 0);
s->commit(ch2, 0);
s->commit(ch3, 1);
\end{code}

\subsection{Why recomputation is almost for free}

An absolutely fundamental property of the above hybrid is that an
equivalent space is computed without performing any constraint
propagation! Remember: committing just reposts constraints but
does not perform constraint propagation.

Reconsider the example from \autoref{fig:m:search:hybrid}.
Search has just failed at node~4 and must compute a space for
node \texttt{?}.

Suppose that only cloning but no recomputation is used. Then, a
clone of the space for node~3 is created (from the clone that is
stored in node~3) and that clone is committed to the first
alternative of $\mathtt{d3}$ (this corresponds to the slightly
thicker edge in \autoref{fig:m:search:hybrid}).  After that,
constraint propagation is performed (by executing the \?status()?
function of a space, see also \autoref{tip:m:started:status}) to
find out if and how search must continue. That is: there is one
\?clone?  operation, one \?commit? operation, and one \?status?
operation to perform constraint propagation.

With hybrid recomputation, one \?clone? operation, three
\?commit? operations, and one \?status? operation to perform
constraint propagation are needed (as shown above). The good news
is that \?commit? operations are very cheap (most often, just
modifying a single variable or posting a constraint). What is
essential is that in both cases only a \emph{single} \?status?
operation is executed. Hence, the cost for constraint propagation
during hybrid recomputation turns out to be not much higher than
the cost without recomputation.

For hybrid recomputation, some additional propagation might have
to be done compared to cloning. As it turns out, the additional
cost is rather small. This is due to the fact that constraint
propagation executes all propagators that might be able to remove
values for variables until no more propagation is possible (a
fixpoint for the propagators is computed). Due to the
approximative nature of ``might be able to remove values'' the
additional propagation tends to show only a very small increase
in runtime.


\subsection{Adaptive recomputation}

Consider the case that a search engine finds a failed node. That
means that some brancher has made an erroneous decision and now
search has to recover from that decision. It is quite likely that
not only the last decision is wrong but that the decision that
lead to failure is somewhere higher up in the search tree. With
other words, it is quite likely that search following a
depth-first left-most strategy must explore an entire failed
subtree to recover from the erroneous decision.  In that case it
would be better for hybrid recomputation if there was a clone
close to the failed node rather than far away.

To optimize recomputation in this example scenario, Gecode uses
\emph{adaptive recomputation}: if a node must be recomputed,
adaptive recomputation creates an additional clone in the middle
of the recomputation path. A clone created during adaptive
recomputation is likely to be a good investment.  Most likely, an
entire failed subtree will be explored. Hence, the clone will be
reused several times for reducing the amount of constraint
propagation during recomputation.

More information about search based on recomputation (although
not using choices) can be found in~\cite{Schulte:LNAI:2002}.
Search using choices has been inspired by batch
recomputation~\cite{components} and decomposition-based
search~\cite{DecoSearch}. For an empirical evaluation of
different techniques for search,
see~\cite{ReischukSchulteEa:CP:2009}. 

\subsection{Controlling recomputation}

Hybrid and adaptive recomputation can be easily controlled by two
integers $c_d$ (\emph{commit distance})
and $a_d$ (\emph{adaptive distance}).  The value for $c_d$ controls how
many clones are created during exploration: a search engine
creates clones during exploration to ensure that recomputation
executes at most $c_d$ commit operations. The value for $a_d$
controls adaptive recomputation: only if the clone for
recomputation is more than $a_d$ commit operations away from the
node to be recomputed, adaptive recomputation is used. 

Values for $c_d$ and $a_d$ are used to configure the behavior of
search engines using hybrid and adaptive recomputation, see more
in the next Section.

The number of commit operations as distance measure is
approximately the same as the length of a path in the search
tree. It is only an approximation as search engines use
additional techniques to avoid some unused clone and commit
operations.

\tip{Values for $c_d$ and $a_d$}{ 
  If $c_d=1$, recomputation is never used (you might not want
  to try that for any other reason but curiosity; it takes too
  much memory to be useful). Likewise, to switch off cloning, you
  can use a value for $c_d$ that is larger than the expected
  depth of the search tree. If $a_d\geq c_d$, adaptive
  recomputation is never used.
}


\section{Parallel search}
\label{sec:m:search:parallel}

Parallel search has but one motivation: try to make search more
efficient by employing several threads (or workers) to explore
different parts of the search tree in parallel.

Gecode uses a standard work-stealing architecture for parallel
search: initially, all work (the entire search tree to be
explored) is given to a single worker for exploration, making the
worker busy. All other workers are initially idle, and try to
steal work from a busy worker.  Stealing work means that part of
the search tree is given from a busy worker to an idle worker
such that the idle worker can become busy itself. If a busy
worker becomes idle, it tries to steal new work from a busy
worker.

As work-stealing is indeterministic (depending on how threads are
scheduled, machine load, and other factors), the work that is
stolen varies over different runs for the very same problem: an
idle worker could potentially steal different subtrees from
different busy workers. As different subtrees contain different
solutions, it is indeterministic which solution is found first.

When using parallel search one needs to take the following facts
into account (note that some facts are not particular to
parallel search, check \autoref{tip:m:search:wmp}: they are just
more likely to occur):
\begin{itemize}
\item The order in which solutions are found might be different
  compared to the order in which sequential search finds
  solutions. Likewise, the order in which solutions are found
  might differ from one parallel search to the next. This is just
  a direct consequence of the indeterministic nature of parallel
  search.
\item Naturally, the amount of search needed to find a first
  solution might differ both from sequential search and among
  different parallel searches. Note that this might actually lead
  to super-linear speedup (for $n$ workers, the time to find a
  first solution is less than $1/n$ the time of sequential
  search) or also to real slowdown.
\item For best solution search, the number of solutions until a
  best solution is found as well as the solutions found are
  indeterministic. First, any better solution is legal (it does
  not matter which one) and different runs will sometimes be
  lucky (or not so lucky) to find a good solution rather quickly.
  Second, as a better solution prunes the remaining search space
  the size of the search space depends crucially on how quickly
  good solutions are found.
\item As a corollary to the above items, the deviation in runtime
  and number of nodes explored for parallel search can be quite
  high for different runs of the same problem.
\item Parallel search needs more memory. As a rule of thumb, the
  amount of memory needed scales linearly with the number of
  workers used.
\item For parallel search to deliver some speedup, the search
  tree must be sufficiently large. Otherwise, not all threads
  might be able to find work and idle threads might slow down
  busy threads by the overhead of unsuccessful work-stealing.
\item From all the facts listed, it should be clear that for
  depth-first left-most search for just a single solution it is
  notoriously difficult to obtain consistent speedup. If the
  heuristic is very good (there are almost no failures), sequential
  left-most depth-first search is optimal in exploring the single
  path to the first solution. Hence, all additional work will be
  wasted and the work-stealing overhead might slow down the
  otherwise optimal search.
\end{itemize}

\tip{Be optimistic about parallel search}{%
  After reading the above list of facts you might have come to
  the conclusion that parallel search is not worth it as it does
  not exploit the parallelism of your computer very well. Well,
  why not turn the argument upside down: your machine will almost
  for sure have more than a single processing unit and maybe
  quite some. With sequential search, all units but one will be
  idle anyway.
  
  The point of parallel search is to make search go faster.  It
  is not to perfectly utilize your parallel hardware.  Parallel
  search makes good use (and very often excellent use for large
  problems with large search trees) of the additional processing
  power your computer has anyway.

\begin{figure}
\begin{cmd}
GolombRuler
        m[12] = {0, 1, 3, 7, 12, 20, 30, 44, 65, 80, 96, 122}
        ... (additional solutions omitted)
        m[12] = {0, 2, 6, 24, 29, 40, 43, 55, 68, 75, 76, 85}

Initial
        propagators: 67
        branchers:   1

Summary
        runtime:      15.349 (15349.000000 ms)
        solutions:    17
        propagations: 584967706
        nodes:        3708507
        failures:     1854221
        peak depth:   52
        peak memory:  1636 KB
\end{cmd}
\caption{Output for golomb rulers with eight workers}
\label{fig:m:search:out:8}
\end{figure}



  For example, on my machine with eight cores and using Gecode 3.4.0, running
  \gecoderef[example]{golomb-ruler} for size $12$ as follows
\begin{cmd}
golomb-ruler.exe -threads 8 12
\end{cmd}
  prints something like shown in \autoref{fig:m:search:out:8}.

\begin{figure}
\begin{cmd}
GolombRuler
        m[12] = {0, 1, 3, 7, 12, 20, 30, 44, 65, 80, 96, 122}
        ... (additional solutions omitted)
        m[12] = {0, 2, 6, 24, 29, 40, 43, 55, 68, 75, 76, 85}

Initial
        propagators: 67
        branchers:   1

Summary
        runtime:      1:52.336 (112336.000000 ms)
        solutions:    16
        propagations: 813022663
        nodes:        5313357
        failures:     2656663
        peak depth:   57
        peak memory:  262 KB
\end{cmd}
\caption{Output for golomb rulers with one worker}
\label{fig:m:search:out:1}
\end{figure}

Compared to sequential search where one gets something like shown
in \autoref{fig:m:search:out:1} one gets a speedup of $7.3$.  }

Parallel search is controlled by the number of threads (or
workers) used for search. If a single worker is requested,
sequential search is used. The number of threads to be used for
search is controlled by the search options passed to a search
engine, see the following section for details.

\tip{Do not optimize by branching alone}{%
\label{tip:m:search:parbab}%
\begin{samepage}
  A common modeling technique for optimization problems that does
  not work for parallel search is the following. Suppose, one has
  a variable \?c? for the cost of a problem and one wants to
  minimize the cost. Then, one could use the following code
  fragment
\begin{code}
branch(home, c, INT_VAL_MIN());
\end{code}
which will try the values for \?c? in increasing order.
\end{samepage}

With sequential search, searching for the first solution with a
standard depth-first left-most search engine will deliver a
best solution, that is, a solution with least cost for \?c?.

With parallel search, the first solution found might of course
not be a best one. Hence, instead of using plain left-most
depth-first search, one should use best solution search with a
proper constrain function that guarantees that \?c? will be
minimized. This will as always guarantee that the last solution
found is the best.

For an example, see the naive model for the bin packing case
study in \autoref{sec:c:bpp:naive} where a branching first
branches on the number of required bins.
}



\section{Search engines}
\label{sec:m:search:simple}

\begin{important}
Do not forget to add
\begin{code}
#include <gecode/search.hh>
\end{code}
to your program when you want to use search engines.
\end{important}

\begin{figure}
\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\multicolumn{1}{|c|}{member} & 
\multicolumn{1}{c|}{type} & 
\multicolumn{1}{c|}{meaning} \\
\hline\hline
\?propagate? & \?unsigned long int? & propagators executed\\
\hline
\?fail? & \?unsigned long int? & failed nodes explored\\
\?node? & \?unsigned long int? & nodes explored\\
\hline
\?depth? & \?unsigned long int? & maximal depth of explored tree\\
\hline
\?memory? & \?size_t? & peak memory allocated\\
\hline
\end{tabular}
\end{center}
\caption[Search statistics]{Search statistics (partial)}
\label{fig:m:search:statistics}
\end{figure}

All search engines in Gecode are parametric (are templates) with
respect to a subclass \?T? of \gecoderef[class]{Space} (for
example, \?SendMoreMoney? in \autoref{sec:m:started:first}).
Moreover, all search engines share the same interface:
\begin{itemize}
\item The search engine is initialized by a constructor taking a
  pointer to an instance of the space subclass \?T? as argument.
  By default, the search engine takes a clone of the space
  passed. 
  
  This behavior can be changed, as can be other aspects of a
  search engine, see \autoref{sec:m:search:options}.
\item A next solution can be requested by a \?next()? member
  function. If no more solutions exist, \?next()? returns
  \?NULL?. Otherwise, the engine returns a solution which again
  is an instance of \?T?. The client of the search engine is
  responsible for deleting solutions.
\item A search engine can be asked for statistics information by
  the \?statistics()? member function. The function returns an
  object of type \gecoderef[class]{Search::Statistics}. The
  statistics information provided is partially summarized in
  \autoref{fig:m:search:statistics}.
\item A search engine can be queried by \?stopped()? whether the
  search engine has been stopped by a \emph{stop object}. Stop
  objects are discussed in \autoref{sec:m:search:stop}.
\item The destructor deletes all resources used by the search
  engine.
\end{itemize}

Note that search engines use pointers to objects rather than
references to objects. The reason is that some pointers might be
\?NULL?-pointers (for example, if \?next()? fails to find a
solution) and that users of search engines have to think about
deleting solutions computed by search engines.

\begin{figure}
\begin{center}
\begin{tabular}{|l|l|l|c|c|}
\hline
\multicolumn{1}{|c|}{engine} & 
\multicolumn{1}{c|}{shortcut} & 
\multicolumn{1}{c|}{exploration} & 
best solution &
parallel \\
\hline\hline
\?DFS? & \?dfs? & depth-first left-most & & \YES\\
\hline
\?BAB? & \?bab? & branch-and-bound & \YES & \YES\\
\?RBS? & \?rbs? & depth-first left-most restart & \YES& \YES\\
\hline
\end{tabular}
\end{center}
\caption{Available search engines}
\label{fig:m:search:engine}
\end{figure}

For each search engine there also exists a convenient shortcut
function (of the same name but entirely in lowercase letters)
that returns either the first solution or, in the case of best
solution search, the last (and hence best) solution. The
available search engines are summarized in
\autoref{fig:m:search:engine}. 

\?BAB? continues search when a solution is found by adding a
constraint (through the \?constrain()? function as discussed in
\autoref{sec:m:started:search-best}) to search for a better
solution to all remaining nodes of the search tree. \?RBS?
restarts the search after the constraint has been added to the
root node of the search tree (again, by using the \?constrain()?
function).



\subsection{Search options}
\label{sec:m:search:options}

All search engines can take a default option value of type 
\gecoderef[class]{Search::Options} when being created. The
options are summarized in \autoref{fig:m:search:options}.
The default values for the options are defined in the namespace
\gecoderef[namespace]{Search::Config}. 

\begin{figure}
\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\multicolumn{1}{|c|}{member} & 
\multicolumn{1}{c|}{type} & 
\multicolumn{1}{c|}{meaning} \\
\hline\hline
\?threads? & \?double? & number of parallel threads to use\\
\hline
\?c_d? & \?unsigned int? & commit recomputation distance\\
\?a_d? & \?unsigned int? & adaptive recomputation distance\\
\hline
\?clone? & \?bool? & whether engine uses a clone when created\\
\hline
\?stop? & \?Search::Stop*? & stop object (\?NULL? if none)\\
\hline
\end{tabular}
\end{center}
\caption{Search options}
\label{fig:m:search:options}
\end{figure}

The meaning of the values for the search options are
straightforward but for \?threads?. Assume that your computer has
$m$ processing units\footnote{This is a very rough
  characterization: a processing unit could be a CPU, a processor
  core, or a multi-threading unit. If you want to find out how
  many processing units Gecode believes your machine has, invoke
  the configuration summary as described in
  \autoref{tip:m:comfy:conf}.} and that the value for \?threads? is
$n$.
\begin{itemize}
\item If $n=0$, then $m$ threads are used (as many as available
  processing units).
\item If $n\geq 1$, then $n$ threads are used (absolute number
  of threads to be used).
\item If $n\leq -1$, then $m+n$ threads are used (absolute
  number of processing units not to be used). For example, when
  $n=-6$ and $m=8$, then $2$ threads are used.
\item If $0<n<1$, then $n\cdot m$ threads are used (relative
  number of processing units to be used). For example, when
  $n=0.5$ and $m=8$, then $4$ threads are used.
\item If $-1<n<0$, then $(1+n)\cdot m$ threads are used
  (relative number of processing units not to be used). For
  example, when $n=-0.25$ and $m=8$, then $6$ threads are used.
\end{itemize}
Note that all values are of course rounded and that at least one
thread will be used.


\subsection{Stop objects}
\label{sec:m:search:stop}

A stop object (a subclass of \gecoderef[class]{Search::Stop})
implements a single virtual member function \?stop()? that takes
two arguments, the first of type
\gecoderef[class]{Search::Statistics} and the second of type
\gecoderef[class]{Search::Options},
and returns either \?true?  or \?false?. If a stop object is passed
to a search engine (by passing it as \?stop? member of a search
option), the search engine calls the \?stop()? function of the
stop object before every exploration step and passes the current
statistics as argument.  If the \?stop()? function returns true,
the search engine stops its execution.

When a search engine is stopped its \?next()? function returns
\?NULL? as solution. To find out whether a search engine has been
stopped or whether there are no more solutions, the \?stopped()?
member function of a search engine can be used. Search can be
resumed by calling \?next()? again after the stop object has been
modified (for example, by increasing the node or time limit).

Note that when using several threads for parallel search, each
thread checks whether it is stopped independently using the very
same stop object. If one thread is stopped, then the entire
search engine is stopped. 

\begin{figure}
\begin{center}
\begin{tabular}{|l|l|}
\hline
\multicolumn{1}{|c|}{class} & 
\multicolumn{1}{c|}{description} \\
\hline\hline
\gecoderef[class]{Search::MemoryStop} & memory limit exceeded\\
\hline
\gecoderef[class]{Search::NodeStop} & node limit exceeded\\
\hline
\gecoderef[class]{Search::FailStop} & failure limit exceeded\\
\hline
\gecoderef[class]{Search::TimeStop} & time limit exceeded\\
\hline
\end{tabular}
\end{center}
\caption{Predefined stop objects}
\label{fig:m:search:stop}
\end{figure}


Gecode provides several predefined stop objects, see
\gecoderef[group]{TaskModelSearchStop}. For an overview see
\autoref{fig:m:search:stop}.


\tip{Number of threads for stop objects}{%
As mentioned above, each thread in parallel search uses the very same
stop object. For example, when using the predefined
\gecoderef[class]{Search::NodeStop} stop object with a node limit
of $n$, then each thread can explore up to $n$ nodes.

If you want to have finer control (say, only allow each thread to
explore up to $n/m$ nodes where  $m$ is the number of threads)
you can use the search option argument that is passed as the
second argument to the \?stop? member function to scale the node
limit according to the number of available threads.
}


